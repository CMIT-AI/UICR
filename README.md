# UICR

## 简介

人机交互界面组件识别在自动化领域中有很重要的使用场景。 自动化控制程序需要先识别控制过程中的被控目标，然后根据被控制目标的类型或者属性来针对性的实施需要的操作或者定义好的操作。

现有的自动化控制程序主要针对桌面端应用程序、Web 端应用程序、移动端应用或者操作系统。 针对桌面端应用程序成熟的自动化控制程序有诸如UIAutomation、QTP等，针对Web端应用程序有Selenium、Playwright等， 针对移动端应用有Appnium、MobileRunner等，针对操作系统目前尚未有成熟并大规模使用的自动化控制程序。 现有的解决方案大部分都依赖于操作系统本身对应用程序组件的解析（如ID，属性等）或者依赖于浏览器对HTML页面渲染的数据解析， 一旦UI界面的结构、样式或者属性等发生变化，自动化程序便无法识别出需要控制的组件。这个问题将导致自动化控制的成本激增。 尤其在现代程序开发模式进入敏捷开发、快速迭代的情况下，UI界面的变化更加频繁。

通过图像识别的方式，识别出组件类型、属性以及关系，可以解决上述问题。 自动化控制程序将不再需要固定的组件属性或者组件ID既可以找到需要控制的组件。 即使UI界面发生很大变化，也可以用更符合人类的操作模式来很快的更新控制程序以适配新的UI界面。

我们希望机器可以识别 Windows 图形界面上的众多元素，比如文字、按键、输入等。 以此为基础，纯文本的 GUI 自动化测试用例脚本就可以实现；更进一步，以自然语言编写的 GUI 测试用例可以直接运行。 目前我们已经训练出了3个模型，可以识别的 Windows 图形界面组件种类如下表所示，大多数的准确率都达到了95%以上。

## 使用说明

### 安装工具

git，docker

### 克隆代码

git clone https://github.com/CMIT-AI/UICR.git

### Build

建议以docker形式运行

docker build -t uicr:latest -f Dockerfile
docker run -d --gpus all -p 39060:39060 -v {your/host/path}:/cmit/data

### 配置

配置文件格式参考 config/config.json，放在{your/host/path}下

### 模型文件

首先下载模型文件，并放在{your/host/path}/weights下

访问http://{your/uicr/ip}:39060/docs，利用api接口加载模型

## 感谢

https://github.com/WongKinYiu/yolov7